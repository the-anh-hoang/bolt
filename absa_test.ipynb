{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was amazing, but the service was terrible.\n",
      "Aspect: food\n",
      "Sentiment: Positive, Scores: [[2.0620544e-03 7.0742110e-04 9.9723047e-01]]\n",
      "--------------------------------------------------\n",
      "Review: The food was amazing, but the service was terrible.\n",
      "Aspect: service\n",
      "Sentiment: Negative, Scores: [[9.9959868e-01 2.6756665e-04 1.3377918e-04]]\n",
      "--------------------------------------------------\n",
      "Review: The food was amazing, but the service was terrible.\n",
      "Aspect: ambiance\n",
      "Sentiment: Neutral, Scores: [[0.08148709 0.761913   0.1565999 ]]\n",
      "--------------------------------------------------\n",
      "Review: Delivery was quick, but the pizza was too salty.\n",
      "Aspect: food\n",
      "Sentiment: Neutral, Scores: [[0.36527795 0.47401786 0.16070414]]\n",
      "--------------------------------------------------\n",
      "Review: Delivery was quick, but the pizza was too salty.\n",
      "Aspect: service\n",
      "Sentiment: Neutral, Scores: [[0.01530731 0.9164225  0.06827018]]\n",
      "--------------------------------------------------\n",
      "Review: Delivery was quick, but the pizza was too salty.\n",
      "Aspect: ambiance\n",
      "Sentiment: Neutral, Scores: [[0.00386311 0.9915774  0.00455959]]\n",
      "--------------------------------------------------\n",
      "Review: The ambiance was fantastic, and the waiter was very friendly!\n",
      "Aspect: food\n",
      "Sentiment: Neutral, Scores: [[0.00170369 0.99678063 0.00151566]]\n",
      "--------------------------------------------------\n",
      "Review: The ambiance was fantastic, and the waiter was very friendly!\n",
      "Aspect: service\n",
      "Sentiment: Neutral, Scores: [[9.1794034e-04 9.9750876e-01 1.5733092e-03]]\n",
      "--------------------------------------------------\n",
      "Review: The ambiance was fantastic, and the waiter was very friendly!\n",
      "Aspect: ambiance\n",
      "Sentiment: Positive, Scores: [[4.0837280e-05 9.6543954e-05 9.9986255e-01]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"yangheng/deberta-v3-large-absa-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "def extract_aspects(review):\n",
    "    # Placeholder function: Implement your aspect extraction logic here\n",
    "    # Example: return ['food', 'service'] if those aspects are present in the review\n",
    "    return ['food','service','ambiance']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "reviews = [\n",
    "    \"The food was amazing, but the service was terrible.\",\n",
    "    \"Delivery was quick, but the pizza was too salty.\",\n",
    "    \"The ambiance was fantastic, and the waiter was very friendly!\"\n",
    "]\n",
    "\n",
    "for review in reviews:\n",
    "    aspects = extract_aspects(review)\n",
    "    for aspect in aspects:\n",
    "        inputs = tokenizer(review, aspect, return_tensors=\"pt\", truncation=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        sentiment_scores = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment_label = torch.argmax(sentiment_scores, dim=-1).cpu().item()\n",
    "        labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "        predicted_label = labels[sentiment_label]\n",
    "        print(f\"Review: {review}\")\n",
    "        print(f\"Aspect: {aspect}\")\n",
    "        print(f\"Sentiment: {predicted_label}, Scores: {sentiment_scores.cpu().numpy()}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
